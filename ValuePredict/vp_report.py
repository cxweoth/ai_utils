import os
import shap
import pandas as pd
import matplotlib.pyplot as plt
from autogluon.tabular import TabularPredictor


class ValuePredictReport:
    def __init__(self, train_data_path, id_col, label, report_folder):
        self.train_data = pd.read_csv(train_data_path)
        self.id_col = id_col
        self.label = label
        self.report_folder = report_folder
        self.model_path = os.path.join(report_folder, "models")
        self.vp_report_path = os.path.join(report_folder, "vp_report.md")
        self.eval_metric = "mean_squared_error"

        # ç§»é™¤ ID æ¬„ä½ä¸¦ä¿å­˜
        self.train_id = self.train_data[self.id_col]
        self.train_data.drop(columns=[self.id_col], inplace=True)
        self.original_features = [col for col in self.train_data.columns if col != self.label]
        self.vp_report_lines = []

    def generate_report(self):
        print("Generating Report...")
        report_lines, recommended_features = self.generate_basic_part() 
        self.vp_report_lines.extend(report_lines)
        self.save_report()
        print("Report Saved at:", self.vp_report_path)

    def save_report(self):
        with open(self.vp_report_path, "w") as f:
            f.write("\n".join(self.vp_report_lines))

    def generate_basic_part(self):
        predictor = TabularPredictor(label=self.label, path=self.model_path, eval_metric=self.eval_metric)\
            .fit(self.train_data)

        leaderboard_df = predictor.leaderboard(self.train_data, silent=True)
        feature_importance_df = predictor.feature_importance(self.train_data)
        used_features = predictor.feature_metadata.get_features()
        unused_features = [f for f in self.original_features if f not in used_features]

        # SHAP å¯è¦–åŒ–
        X, _ = predictor.load_data_internal('train')
        lightgbm_model_name = next(m for m in predictor.model_names() if "LightGBM" in m)
        print(f"ä½¿ç”¨ SHAP çš„æ¨¡å‹ï¼š{lightgbm_model_name}")

        lgbm_model = predictor._trainer.load_model(lightgbm_model_name).model
        explainer = shap.TreeExplainer(lgbm_model)
        shap_values = explainer.shap_values(X)

        # SHAP summary plot
        shap_summary_plot_path = os.path.join(self.report_folder, "shap_summary_plot.png")
        plt.figure()
        shap.summary_plot(shap_values, X, show=False)
        plt.tight_layout()
        plt.savefig(shap_summary_plot_path)

        # SHAP bar plot
        shap_bar_plot_path = os.path.join(self.report_folder, "shap_bar_plot.png")
        plt.figure()
        shap.summary_plot(shap_values, X, plot_type="bar", show=False)
        plt.tight_layout()
        plt.savefig(shap_bar_plot_path)

        # å»ºç«‹å ±å‘Šå…§å®¹
        report_lines = [
            "# AutoML é æ¸¬ä»»å‹™å ±å‘Š",
            "",
            "## ğŸ¯ é æ¸¬ç›®æ¨™",
            f"- é æ¸¬æ¬„ä½ï¼š**{self.label}**",
            f"- è¨“ç·´è³‡æ–™ç­†æ•¸ï¼š{len(self.train_data)}",
            f"- åŸå§‹ç‰¹å¾µæ•¸é‡ï¼š{len(self.original_features)}",
            "",
            "## ç‰¹å¾µåˆ†æ",
            "### Top 30 é‡è¦ç‰¹å¾µ",
            feature_importance_df.head(30).to_markdown(index=True),
            "",
            "| æ¬„ä½ | èªªæ˜ |",
            "|------|------|",
            "| importance | ç‰¹å¾µé‡è¦æ€§åˆ†æ•¸ï¼Œè¡¨ç¤ºè©²ç‰¹å¾µå°æ¨¡å‹é æ¸¬çš„å½±éŸ¿ç¨‹åº¦ |",
            "| stddev | ç‰¹å¾µé‡è¦æ€§çš„æ¨™æº–å·®ï¼Œè¡¨ç¤ºä¼°è¨ˆçš„ä¸ç¢ºå®šæ€§ |",
            "| p_value | çµ±è¨ˆé¡¯è‘—æ€§æª¢é©—çš„ p å€¼ |",
            "| n | ç”¨æ–¼è¨ˆç®—çš„é‡è¦æ¨£æœ¬æ•¸ |",
            "| p99_high / p99_low | 99% ç½®ä¿¡å€é–“ä¸Šä¸‹é™ |",
            "",
            "> **ç½®ä¿¡å€é–“èªªæ˜**ï¼šç¯„åœå°è¡¨ç¤ºä¼°è¨ˆç²¾ç¢ºï¼›è‹¥ä¸åŒ…å«é›¶ï¼Œå‰‡å…·çµ±è¨ˆé¡¯è‘—æ€§ã€‚",
            "",
            "### ğŸ§  SHAP æ¨¡å‹è§£é‡‹ï¼ˆåŸºæ–¼ LightGBMï¼‰",
            "#### 1. SHAP Summary Plotï¼ˆé»åœ–ï¼‰",
            f"![summary]({shap_summary_plot_path})",
            "",
            "#### 2. SHAP Feature Importanceï¼ˆæ¢ç‹€åœ–ï¼‰",
            f"![bar]({shap_bar_plot_path})",
            "",
            "> SHAP å¯è¦–åŒ–å¹«åŠ©äº†è§£æ¯å€‹ç‰¹å¾µå°é æ¸¬çš„æ­£è² å½±éŸ¿èˆ‡é‡è¦ç¨‹åº¦ã€‚",
            "",
            "## Baseline æ¨¡å‹è¡¨ç¾",
            "### æ¨¡å‹ä½¿ç”¨ç‰¹å¾µ",
            "```",
            ", ".join(used_features),
            "```",
            "",
            "### æ¨¡å‹æœªä½¿ç”¨ç‰¹å¾µ",
            "```",
            ", ".join(unused_features),
            "```",
            "",
            "### æ¨¡å‹ Baseline Leaderboard",
            leaderboard_df.to_markdown(index=False),
            "",
            "| æ¬„ä½ | èªªæ˜ |",
            "|------|------|",
            "| model | æ¨¡å‹åç¨± |",
            "| score_test / score_val | è² çš„ RMSEï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰ |",
            "| pred_time_* / fit_time | é æ¸¬èˆ‡è¨“ç·´è€—æ™‚ï¼ˆç§’ï¼‰ |",
            "| stack_level | æ¨¡å‹å †ç–Šå±¤ç´š |",
            "| can_infer | æ˜¯å¦å¯ç”¨æ–¼æ¨è«– |",
        ]

        # æ¨è–¦ç‰¹å¾µ
        recommended_features = self.recommend_features(feature_importance_df)

        report_lines.append(f"## æ¨è–¦ç‰¹å¾µ")
        report_lines.append(f"- æ¨è–¦ç‰¹å¾µæ•¸é‡ï¼š{len(recommended_features)}")
        report_lines.append(f"- æ¨è–¦ç‰¹å¾µï¼š")
        report_lines.append(f"  ```")
        report_lines.append(f"  {', '.join(recommended_features)}")
        report_lines.append(f"  ```")

        return report_lines, recommended_features
    
    def recommend_features(self, feature_importance_df, top_k=30):
        # æ ¹æ“š importance é¸å‡ºå‰ top_k ç‰¹å¾µ
        importance_top = feature_importance_df.head(top_k).index.tolist()
        return importance_top
